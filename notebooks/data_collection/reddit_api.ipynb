{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb346bc2",
   "metadata": {},
   "source": [
    "## __Reddit Platform: Same-sex marriage__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f50f3c9",
   "metadata": {},
   "source": [
    "### __General__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732301ec",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5598d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, json\n",
    "from datetime import datetime \n",
    "from dotenv import load_dotenv\n",
    "import praw\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from utils.helpers import unique_posts_videos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339a9113",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290a4e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reddit functions\n",
    "def search_greek_reddit_posts(reddit_object, keywords, limit=10, max_requests_per_min=90):\n",
    "    \"\"\"\n",
    "    Search Reddit for Greek-language posts using a keyword list,\n",
    "    respecting Reddit's 100 requests/minute API rate limit.\n",
    "    \"\"\"\n",
    "    thread_data = []\n",
    "    request_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    def check_rate_limit():\n",
    "        nonlocal request_counter, start_time\n",
    "        elapsed = time.time() - start_time\n",
    "        if request_counter >= max_requests_per_min:\n",
    "            sleep_time = max(0, 60 - elapsed)\n",
    "            if sleep_time > 0:\n",
    "                print(f\"Rate limit hit. Sleeping for {sleep_time:.1f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "            start_time = time.time()\n",
    "            request_counter = 0\n",
    "\n",
    "    sorting_options = [\"relevance\", \"top\", \"new\"]\n",
    "\n",
    "    for keyword in keywords:\n",
    "        for sorting_option in sorting_options:\n",
    "            check_rate_limit()\n",
    "            print(f\"Searching for keyword: {keyword}\")\n",
    "            try:\n",
    "                submissions = list(reddit_object.subreddit(\"greece\").search(keyword, sort=sorting_option, limit=limit))\n",
    "                request_counter += 1 # one API call per keyword\n",
    "            except Exception as e:\n",
    "                print(f\"Search failed for '{keyword}': {e}\")\n",
    "                continue\n",
    "\n",
    "            for submission in submissions:\n",
    "                try:\n",
    "                    title = submission.title\n",
    "                    body = submission.selftext or \"\"\n",
    "                    author_obj = submission.author\n",
    "                    username = author_obj.name if author_obj else \"[deleted]\"\n",
    "\n",
    "                    if keyword.lower() in title.lower():\n",
    "                        if detect(title) == \"el\":\n",
    "                            print(f\"Found Greek post: {title[:50]}...\")\n",
    "                            thread_data.append({\n",
    "                                \"id\": submission.id,\n",
    "                                \"title\": title,\n",
    "                                \"content\": body,\n",
    "                                \"subreddit\": str(submission.subreddit),\n",
    "                                \"created_utc\": submission.created_utc,\n",
    "                                \"like_count\": submission.ups,\n",
    "                                \"num_comments\": submission.num_comments,\n",
    "                                \"url\": submission.url,\n",
    "                                \"author\": str(author_obj),\n",
    "                                \"username\": username \n",
    "                            })\n",
    "\n",
    "                except LangDetectException:\n",
    "                    continue\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing submission: {e}\")\n",
    "                    continue\n",
    "\n",
    "    return thread_data\n",
    "\n",
    "def fetch_comments_forest(reddit_object, post_ids, max_requests_per_min=90):\n",
    "    \"\"\"\n",
    "    Fetch comments in tree structure with hierarchical IDs for a list of post IDs.\n",
    "    \"\"\"\n",
    "    all_comments = []\n",
    "    request_counter = 0\n",
    "    start_time = time.time()\n",
    "\n",
    "    def check_rate_limit():\n",
    "        nonlocal request_counter, start_time\n",
    "        elapsed = time.time() - start_time\n",
    "        if request_counter >= max_requests_per_min:\n",
    "            sleep_time = max(0, 60 - elapsed)\n",
    "            if sleep_time > 0:\n",
    "                print(f\"[COMMENTS] Rate limit hit. Sleeping for {sleep_time:.1f} seconds...\")\n",
    "                time.sleep(sleep_time)\n",
    "            request_counter = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "    def index_comment_tree(comment_forest, prefix=\"\"):\n",
    "        indexed = []\n",
    "        for i, comment in enumerate(comment_forest, start=1):\n",
    "            if not hasattr(comment, \"body\"):\n",
    "                continue\n",
    "\n",
    "            hier_id = f\"{prefix}{i}\" if prefix == \"\" else f\"{prefix}.{i}\"\n",
    "\n",
    "            indexed.append({\n",
    "                \"hier_id\": hier_id,\n",
    "                \"reddit_id\": comment.id,\n",
    "                \"author\": comment.author.name if comment.author else None,\n",
    "                \"published_at\": datetime.fromtimestamp(comment.created_utc).isoformat(),\n",
    "                \"body\": comment.body,\n",
    "                \"like_count\": comment.ups,\n",
    "                \"parent_id\": comment.parent_id,\n",
    "                \"depth\": comment.depth,\n",
    "            })\n",
    "\n",
    "            if comment.replies:\n",
    "                indexed.extend(index_comment_tree(comment.replies, prefix=hier_id))\n",
    "        return indexed\n",
    "\n",
    "    for post_id in post_ids:\n",
    "        check_rate_limit()\n",
    "        try:\n",
    "            submission = reddit_object.submission(id=post_id)\n",
    "            request_counter += 1\n",
    "\n",
    "            submission.comments.replace_more(limit=0)\n",
    "            comment_tree = submission.comments\n",
    "            indexed = index_comment_tree(comment_tree)\n",
    "            all_comments.append({\n",
    "                \"post_id\": post_id,\n",
    "                \"comments\": indexed\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching tree for post {post_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "    return all_comments\n",
    "\n",
    "def login_reddit():\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=os.getenv('REDDIT_CLIENT_ID'),\n",
    "        client_secret=os.getenv('REDDIT_SECRET'),\n",
    "        user_agent=os.getenv('USR_AGENT'),\n",
    "        username=os.getenv('REDDIT_USR'),\n",
    "        password=os.getenv('REDDIT_PWD')\n",
    "        )\n",
    "\n",
    "    print(\"Logged in as:\", reddit.user.me())\n",
    "    return reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099232c",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed698112",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() # load .env project file\n",
    "reddit_object = login_reddit() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d904573",
   "metadata": {},
   "source": [
    "### __Search posts__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50724c3",
   "metadata": {},
   "source": [
    "#### Posts/Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07768238",
   "metadata": {},
   "outputs": [],
   "source": [
    "greek_keywords = [\"ομόφυλα ζευγάρια\", \n",
    "                  \"ομόφυλα τεκνοθεσία\", \n",
    "                  \"ισότητα στο πολιτικό γάμο\", \n",
    "                  \"γάμος ομόφυλων\", \n",
    "                  \"γάμος ομόφυλων ζευγαριών\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfdd7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = search_greek_reddit_posts(\n",
    "    reddit_object=reddit_object, \n",
    "    keywords=greek_keywords, \n",
    "    limit=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c8869b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data, duplicates = unique_posts_videos(posts, id_key=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fbc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posts), len(clean_data), len(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9371e8",
   "metadata": {},
   "source": [
    "#### Save"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118c945b",
   "metadata": {},
   "source": [
    "Save the final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0524ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"reddit_api.ipynb\")))) + \"\\\\outputs\\\\api_queried\\\\reddit_api\\\\reddit_scraped_post.json\"\n",
    "\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(posts, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9382bfaa",
   "metadata": {},
   "source": [
    "Clear system and pycache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d9b0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### delete reddit login object\n",
    "del reddit_object\n",
    "\n",
    "### reset environmental variables\n",
    "os.environ[\"REDDIT_CLIENT_ID\"] = \"\"\n",
    "os.environ[\"REDDIT_SECRET\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e88cc28",
   "metadata": {},
   "source": [
    "### __Search comments__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e7c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"reddit_api.ipynb\")))) + \"\\\\outputs\\\\api_queried\\\\reddit_api\\\\reddit_scraped_post.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5a99abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(post_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6fdc86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ids = []\n",
    "for post in data:\n",
    "    post_ids.append(post[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496c7dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a2a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_comments = fetch_comments_forest(reddit_object=reddit_object, post_ids=post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c156b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"reddit_api.ipynb\")))) + \"\\\\outputs\\\\api_queried\\\\reddit_api\\\\reddit_scraped_comments_2.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32e9ca2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(comment_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(test_comments, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
