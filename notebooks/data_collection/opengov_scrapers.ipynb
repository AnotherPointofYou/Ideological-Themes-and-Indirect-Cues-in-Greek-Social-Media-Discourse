{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __OpenGov Platform: Same-sex marriage__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import lxml\n",
    "import json \n",
    "import os\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import logging \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the log file\n",
    "def load_log(log_file_path):\n",
    "    log = {}\n",
    "    if os.path.exists(log_file_path):\n",
    "        with open(log_file_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split(\",\")\n",
    "                if len(parts) == 2:\n",
    "                    p_val, last_cpage = parts\n",
    "                    log[int(p_val)] = int(last_cpage)\n",
    "    else:\n",
    "        print(\"incorrect path\")\n",
    "    return log\n",
    "\n",
    "# update the log file\n",
    "def update_log(p_val, last_cpage):\n",
    "    log[p_val] = last_cpage\n",
    "    with open(log_file_path, \"w\") as f:\n",
    "        for key, val in log.items():\n",
    "            f.write(f\"{key},{val}\\n\")\n",
    "\n",
    "# page scraping logic\n",
    "def scrape_comments(p_val, page, max_retries=3):\n",
    "    full_url = f\"https://www.opengov.gr/ypep/?p={p_val}&cpage={page}#comments\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = requests.get(full_url, headers=headers)\n",
    "            if response.status_code == 429:\n",
    "                print(f\"[429] Rate limited on p={p_val}, page={page}. Sleeping for 60s...\")\n",
    "                time.sleep(60)\n",
    "                retries += 1\n",
    "                continue\n",
    "            elif response.status_code >= 400:\n",
    "                print(f\"[{response.status_code}] Error on p={p_val}, page={page}. Aborting this page.\")\n",
    "                return None # early failure\n",
    "\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            comments = soup.find_all(\"li\", class_=\"comment\")\n",
    "            if not comments:\n",
    "                return False # no comments on this page\n",
    "\n",
    "            all_page_comments = []\n",
    "            for comment in comments:\n",
    "                author = comment.find(\"div\", class_=\"author\")\n",
    "                author_name = author.find(\"strong\").get_text(strip=True) if author else \"Unknown\"\n",
    "                date_published = author.get_text(strip=True).split(\"|\")[0] if author else \"Unknown\"\n",
    "                text = comment.find(\"p\")\n",
    "                article_text = text.get_text(strip=True) if text else \"No text available\"\n",
    "                permalink = comment.find(\"a\", class_=\"permalink\")\n",
    "                comment_url = permalink[\"href\"] if permalink else \"No URL\"\n",
    "\n",
    "                comment_data = {\n",
    "                    \"data_type\": \"Comment in 'opengov.gr' under the curriculum's content\",\n",
    "                    \"author_name\": author_name,\n",
    "                    \"date_published\": date_published,\n",
    "                    \"article_text\": article_text,\n",
    "                    \"URL\": comment_url,\n",
    "                    \"page_found\": page\n",
    "                }\n",
    "                all_page_comments.append(comment_data)\n",
    "\n",
    "            return all_page_comments\n",
    "\n",
    "        except requests.RequestException as e:\n",
    "            print(f\"[ERROR] Network error on p={p_val}, page={page}: {e}. Retrying...\")\n",
    "            time.sleep(10)\n",
    "            retries += 1\n",
    "\n",
    "    print(f\"[FAIL] Max retries reached for p={p_val}, page={page}. Skipping.\")\n",
    "    return None\n",
    "\n",
    "log_file_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\"opengov_scrapers.ipynb\")))) + \"\\\\outputs\\\\logs\\\\scrape_log_opengov_same_sex.txt\"\n",
    "log = load_log(log_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs to scrape\n",
    "site_list = [\n",
    "    \"https://www.opengov.gr/ypep/?p=847\",\n",
    "    \"https://www.opengov.gr/ypep/?p=846\",\n",
    "    \"https://www.opengov.gr/ypep/?p=845\",\n",
    "    \"https://www.opengov.gr/ypep/?p=844\",\n",
    "    \"https://www.opengov.gr/ypep/?p=843\",\n",
    "    \"https://www.opengov.gr/ypep/?p=842\",\n",
    "    \"https://www.opengov.gr/ypep/?p=841\",\n",
    "    \"https://www.opengov.gr/ypep/?p=840\",\n",
    "    \"https://www.opengov.gr/ypep/?p=839\",\n",
    "    \"https://www.opengov.gr/ypep/?p=838\",\n",
    "    \"https://www.opengov.gr/ypep/?p=837\",\n",
    "    \"https://www.opengov.gr/ypep/?p=836\",\n",
    "    \"https://www.opengov.gr/ypep/?p=835\",\n",
    "]\n",
    "\n",
    "#### DEBUG LINES ####\n",
    "# MAX_PAGES_PER_RUN = 2  # Only scrape 2 comment pages for testing\n",
    "#### DEBUG LINES ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in site_list:\n",
    "    try:\n",
    "        p_val = int(url.split(\"?p=\")[-1])\n",
    "    except ValueError:\n",
    "        print(f\"Invalid URL format: {url}\")\n",
    "        continue\n",
    "\n",
    "    start_page = log.get(p_val, 1)\n",
    "    current_page = start_page\n",
    "    site_comments = []\n",
    "\n",
    "    print(f\"\\nðŸ” Scraping p={p_val} from comment page {start_page}...\")\n",
    "\n",
    "    pages_scraped = 0\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # ### DEBUG LINES\n",
    "        # if pages_scraped >= MAX_PAGES_PER_RUN:\n",
    "        #     print(f\"Test cutoff: reached MAX_PAGES_PER_RUN for p={p_val}\")\n",
    "        #     break\n",
    "        # ### DEBUG LINES\n",
    "\n",
    "        page_comments = scrape_comments(p_val, current_page)\n",
    "\n",
    "        if page_comments is None:\n",
    "            print(f\"Stopping early for p={p_val} due to repeated failures or rate limits.\")\n",
    "            break\n",
    "\n",
    "        elif page_comments:\n",
    "            site_comments.extend(page_comments)\n",
    "            print(f\"Scraped {len(page_comments)} comments from p={p_val}, page {current_page}\")\n",
    "            current_page += 1\n",
    "            # ### DEBUG LINES\n",
    "            # pages_scraped += 1\n",
    "            # ### DEBUG LINES\n",
    "            update_log(p_val, current_page)\n",
    "\n",
    "        else:\n",
    "            print(f\"No more comments at p={p_val}, page {current_page}.\")\n",
    "            break\n",
    "\n",
    "    # save\n",
    "    if site_comments:\n",
    "        end_page = current_page - 1\n",
    "        output_filename = f\"opengov_comments_p{p_val}_pages_{start_page}-{end_page}.json\"\n",
    "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(site_comments, f, ensure_ascii=False, indent=2)\n",
    "        print(f\"Saved {len(site_comments)} comments to {output_filename}\")\n",
    "    else:\n",
    "        print(f\"No new comments scraped for p={p_val}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
