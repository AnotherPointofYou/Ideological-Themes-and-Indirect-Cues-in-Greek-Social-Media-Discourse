{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1705e841",
   "metadata": {},
   "source": [
    "### __Visualizations__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766d15e7",
   "metadata": {},
   "source": [
    "#### __Imports__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bc083390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, copy, sys, re\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import textwrap\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('..')))\n",
    "from utils.visualizations import text_language_frequency, plot_horizontal_barplot\n",
    "from utils.text_analysis_functions import data_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139ebba",
   "metadata": {},
   "source": [
    "#### __Data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9a3db079",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reddit\n",
    "reddit_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\".\")))) + \"\\\\working_data\\\\reddit_cleaned.json\"\n",
    "## YouTube\n",
    "youtube_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\".\")))) + \"\\\\working_data\\\\youtube_cleaned.json\"\n",
    "## OpenGov \n",
    "opengov_path = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\".\")))) + \"\\\\working_data\\\\ogov_cleaned.json\"\n",
    "\n",
    "## YouTube\n",
    "with open(youtube_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    youtube_clean = json.load(f)\n",
    "## Reddit\n",
    "with open(reddit_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    reddit_clean = json.load(f)\n",
    "## OpenGov\n",
    "with open(opengov_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    ogov_clean = json.load(f) \n",
    "\n",
    "final_table = pd.read_csv(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(\".\")))) + \"\\\\working_data\\\\transformed_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8eb15dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_plain_comments = []\n",
    "for com in youtube_clean:\n",
    "    for dic in com[\"comments\"]:\n",
    "        youtube_plain_comments.append(dic[\"body\"])\n",
    "\n",
    "ogov_plain_comments = []\n",
    "for com in ogov_clean:\n",
    "    ogov_plain_comments.append(com[\"article_text\"])\n",
    "\n",
    "reddit_plain_comments = []\n",
    "for com in reddit_clean:\n",
    "    for dic in com[\"comments\"]:\n",
    "        reddit_plain_comments.append(dic[\"body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fbf1ea5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "all_comments.extend(reddit_plain_comments)\n",
    "all_comments.extend(youtube_plain_comments)\n",
    "all_comments.extend(ogov_plain_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4086bb",
   "metadata": {},
   "source": [
    "#### __Preprocessing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4873099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users_yt = []\n",
    "for i in youtube_clean:\n",
    "    for j in i[\"comments\"]:\n",
    "        all_users_yt.append(j[\"author_id\"])\n",
    "\n",
    "all_users_reddit = []\n",
    "for i in reddit_clean:\n",
    "    for j in i[\"comments\"]:\n",
    "        all_users_reddit.append(j[\"author_id\"])\n",
    "\n",
    "all_users_ogov = []\n",
    "for i in ogov_clean:\n",
    "    all_users_ogov.append(i[\"author_id\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1581fa8",
   "metadata": {},
   "source": [
    "#### __Results__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_user_comment_counts(data_dict, title=\"User Comment Frequency\", wrap_width=30, top_n=None):\n",
    "    \"\"\"\n",
    "    Plots a horizontal bar chart of user comment frequencies.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): Dictionary of {user: count}\n",
    "        title (str): Title of the plot\n",
    "        wrap_width (int): Max width before wrapping user names\n",
    "        top_n (int, optional): Limit to top N users by count\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(data_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    if top_n:\n",
    "        sorted_items = sorted_items[:top_n]\n",
    "\n",
    "    users, counts = zip(*sorted_items)\n",
    "    wrapped_users = [\"\\n\".join(textwrap.wrap(str(user), wrap_width)) for user in users]\n",
    "    y_pos = range(len(wrapped_users))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 0.5 * len(wrapped_users)))  # Dynamic height\n",
    "    bars = ax.barh(y_pos, counts, color='skyblue')\n",
    "    ax.set_yticks(y_pos)\n",
    "    ax.set_yticklabels(wrapped_users)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_ylabel(\"User id\")\n",
    "    ax.set_xlabel(\"Number of Comments\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "    for bar, count in zip(bars, counts):\n",
    "        width = bar.get_width()\n",
    "        ax.text(width + max(counts)*0.01, bar.get_y() + bar.get_height()/2,\n",
    "                str(count), va='center')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_comment_count_histogram(\n",
    "    data_dict,\n",
    "    title=\"Distribution of User Comment Counts\",\n",
    "    bins='auto',\n",
    "    min_comments=None,\n",
    "    cumulative=False,\n",
    "    percent_y=True,\n",
    "    annotate_bars=True,\n",
    "    show_bin_edges=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots a histogram showing how many users made X number of comments.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): Dictionary of {user: comment_count}\n",
    "        title (str): Title of the plot\n",
    "        bins (int or str): Number of bins or binning strategy for plt.hist()\n",
    "        min_comments (int or None): Filter out users with fewer than this many comments\n",
    "        cumulative (bool): Whether to show a cumulative histogram\n",
    "        percent_y (bool): Whether to show y-axis as percentage of users\n",
    "        annotate_bars (bool): Whether to show percentage above each bar\n",
    "        show_bin_edges (bool): Whether to show bin edges as x-axis ticks\n",
    "    \"\"\"\n",
    "    if min_comments is not None:\n",
    "        filtered_counts = [count for count in data_dict.values() if count >= min_comments]\n",
    "    else:\n",
    "        filtered_counts = list(data_dict.values())\n",
    "\n",
    "    if not filtered_counts:\n",
    "        print(\"No users meet the minimum comment threshold.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "\n",
    "    max_count = max(filtered_counts)\n",
    "    bin_edges = range(0, max_count + 5, 5)\n",
    "\n",
    "    n, bins_, patches = plt.hist(\n",
    "        filtered_counts,\n",
    "        bins=bin_edges,\n",
    "        color='mediumseagreen',\n",
    "        edgecolor='black',\n",
    "        cumulative=cumulative,\n",
    "        density=percent_y\n",
    "    )\n",
    "\n",
    "    title_suffix = \" (Cumulative)\" if cumulative else \"\"\n",
    "    ylabel = \"Percentage of Users\" if percent_y else \"Number of Users\"\n",
    "    plt.title(title + title_suffix)\n",
    "    plt.xlabel(\"Number of Comments per User\")\n",
    "    plt.ylabel(ylabel)\n",
    "\n",
    "    if percent_y:\n",
    "        plt.gca().yaxis.set_major_formatter(PercentFormatter(xmax=1))\n",
    "\n",
    "    if show_bin_edges:\n",
    "        plt.xticks(bins_, rotation=45)\n",
    "\n",
    "    if annotate_bars and percent_y:\n",
    "        for count, patch in zip(n, patches):\n",
    "            if count == 0:\n",
    "                continue\n",
    "            height = patch.get_height()\n",
    "            x = patch.get_x() + patch.get_width() / 2\n",
    "            y = height\n",
    "            plt.text(x, y + 0.005, f\"{count * 100:.1f}%\", ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def binned_cumulative_table(data_dict, step=5):\n",
    "    \"\"\"\n",
    "    Groups users into comment count bins and computes cumulative totals.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): {user: comment_count}\n",
    "        step (int): Bin size, e.g., 5 for 0–4, 5–9, etc.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame with bin ranges, counts, and cumulative stats.\n",
    "    \"\"\"\n",
    "    counts = [v for k, v in data_dict.items() if k is not None and v is not None]\n",
    "\n",
    "    if not counts:\n",
    "        return pd.DataFrame(columns=[\"Comments Range\", \"Users in Bin\", \"Cumulative Users\", \"Cumulative %\"])\n",
    "\n",
    "    max_count = max(counts)\n",
    "    total_users = len(counts)\n",
    "\n",
    "    bins = list(range(0, max_count + step, step))\n",
    "    bin_labels = [f\"{start}–{start+step-1}\" for start in bins[:-1]]\n",
    "    bin_counts = [0] * len(bin_labels)\n",
    "\n",
    "    for c in counts:\n",
    "        bin_index = min(c // step, len(bin_counts) - 1)\n",
    "        bin_counts[bin_index] += 1\n",
    "\n",
    "    cumulative_counts = []\n",
    "    cumulative = 0\n",
    "    for count in bin_counts:\n",
    "        cumulative += count\n",
    "        cumulative_counts.append(cumulative)\n",
    "\n",
    "    cumulative_percent = [round(c / total_users * 100, 2) for c in cumulative_counts]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"Comments Range\": bin_labels,\n",
    "        \"Users in Bin\": bin_counts,\n",
    "        \"Cumulative Users\": cumulative_counts,\n",
    "        \"Cumulative %\": cumulative_percent\n",
    "    })\n",
    "\n",
    "    return df\n",
    "\n",
    "def plot_binned_cumulative_table(df, title=\"Cumulative Percentage of Users by Comment\"):\n",
    "    x = df[\"Comments Range\"]\n",
    "    y = df[\"Cumulative %\"]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x, y, marker='o', color='#1f77b4')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Comment Count Range\")\n",
    "    plt.ylabel(\"Cumulative % of Users\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "\n",
    "    y_start = max(0, y.iloc[0] - 5)\n",
    "    y_max = 101\n",
    "    plt.ylim(y_start, y_max)\n",
    "\n",
    "    for xi, yi in zip(x, y):\n",
    "        if yi == 100.0:\n",
    "            continue\n",
    "        plt.text(xi, yi - 3, f\"{yi:.1f}%\", ha='center', va='top', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_multiple_binned_cumulative_tables(\n",
    "    tables: dict,\n",
    "    title=\"Cumulative User Distribution by Comment Bins\",\n",
    "    y_label=\"Cumulative % of Users\"):\n",
    "    \"\"\"\n",
    "    Plots cumulative percentage curves for multiple platforms in one diagram,\n",
    "    with staggered percentage annotations to avoid overlap.\n",
    "\n",
    "    Args:\n",
    "        tables (dict): {label: DataFrame}, each must contain 'Comments Range' and 'Cumulative %'\n",
    "        title (str): Plot title\n",
    "        y_label (str): Y-axis label\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    all_y_values = []\n",
    "\n",
    "    for offset_i, (label, df) in enumerate(tables.items()):\n",
    "        x = df[\"Comments Range\"]\n",
    "        y = df[\"Cumulative %\"]\n",
    "        all_y_values.extend(y)\n",
    "\n",
    "        plt.plot(x, y, marker='o', label=label)\n",
    "\n",
    "        offset = 1 + offset_i * 2\n",
    "\n",
    "        for i, (xi, yi) in enumerate(zip(x, y)):\n",
    "            if i % 2 == 0:\n",
    "                plt.text(xi, yi - offset, f\"{yi:.2f}%\", ha='center', va='top', fontsize=8)\n",
    "\n",
    "    y_min = max(0, min(all_y_values) - 10)\n",
    "    y_max = min(105, max(all_y_values) + 5)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Comment Count Range\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Platform\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def scale_like_counts_to_range(df, column=\"like_count\", target_min=1, target_max=10):\n",
    "    x_min = df[column].min()\n",
    "    x_max = df[column].max()\n",
    "    shift = 0\n",
    "    if x_min < 1:\n",
    "        shift = 1 - x_min\n",
    "        x_min += shift\n",
    "        x_max += shift\n",
    "    shifted = df[column] + shift\n",
    "    normalized = (shifted - x_min) / (x_max - x_min)\n",
    "    scaled = target_min + normalized * (target_max - target_min)\n",
    "    return scaled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9dfce",
   "metadata": {},
   "source": [
    "##### General"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e60510",
   "metadata": {},
   "source": [
    "Scale the scaled likes for reddit and youtube seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8f27045e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table.loc[final_table['platform'] == 'opengov', 'like_scaled'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56c06429",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table['like_scaled_norm'] = (\n",
    "    final_table\n",
    "      .groupby('platform')['like_scaled']\n",
    "      .transform(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0965ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_long = 'από τη στιγμή που τα ομοφυλόφιλα ζευγάρια δεν μπορούν να αποκτήσουν παιδιά δεν δικαιούνται να έχουν το ότι υπάρχουν γονείς ακατάλληλοι δε σημαίνει ότι πρέπει να νομοθετήσουμε να έχουν παιδιά οι λοατκι όπως το ότι υπάρχουν αρτιμελείς άνθρωποι απαράδεκτοι δεν σημαίνει ότι πρέπει να επιδιώκουμε μια κοινωνία ατόμων χωρίς χέρια ή πόδια είναι άλλο να κατανοούμε και να αγκαλιάζουμε τα πάθη τις ιδιαιτερότητες και τις αδυναμίες του καθενός κι άλλο να στρεβλώσουμε τη φύση και τις φυσιολογικές λειτουργίες δεν υπάρχουν καν επαρκείς μελέτες που να συνιστούν ότι είναι ok ένα παιδί να μεγαλώνει χωρίς το ένα πρότυπο γονέα και με το άλλο πρότυπο εις διπλούν τι είναι τα παιδιά πειραματόζωα κατοικίδια τρόπαια χρειάζονται πατέρα και μητέρα δεν μπορεί το εγωιστικό καπρίτσιο των λοατκι να είναι πάνω από τα δικαιώματα των παιδιών'\n",
    "search_medium = 'διαφωνώ κάθετα γάμος είναι η συζυγία άνδρα και γυναίκα δεν μπορούμε με έναν νόμο να αλλάξουμε τη φύση τη βιολογία των ανθρώπων οι κοινωνικές συνέπειες αν ψηφιστεί αυτό το νομοσχέδιο θα είναι ολέθριες ας σεβαστούμε τουλάχιστον τη φύση αν δε θέλουμε να σεβαστούμε τις πατροπαράδοτες αξίες μας'\n",
    "search_short = 'πιστεύω ότι γάμος μπορεί να γίνει μόνο μεταξύ ενός άνδρα και μιας γυναίκας ο γάμος μεταξύ ομοφυλόφιλων δεν φυσιολογικό'\n",
    "\n",
    "found_long = final_table[final_table[\"text\"] == search_long]\n",
    "found_medium = final_table[final_table[\"text\"] == search_medium]\n",
    "found_short = final_table[final_table[\"text\"] == search_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cce935",
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in list(final_table[final_table[\"text_length_bin\"] == \"short\"].sample(n=5)[\"text\"]):\n",
    "    print(\"Short comment: \", comment)\n",
    "\n",
    "for comment in list(final_table[final_table[\"text_length_bin\"] == \"medium\"].sample(n=5)[\"text\"]):\n",
    "    print(\"Medium comment: \", comment)\n",
    "\n",
    "for comment in list(final_table[final_table[\"text_length_bin\"] == \"long\"].sample(n=5)[\"text\"]):\n",
    "    print(\"Long comment: \", comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d59b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = pd.crosstab(\n",
    "    index=[final_table['platform'], final_table['text_length_bin']],\n",
    "    columns=final_table['period']\n",
    ")\n",
    "\n",
    "cross = cross.reset_index()\n",
    "\n",
    "platform_totals = (\n",
    "    cross.groupby('platform')[['pre', 'during', 'post']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "platform_totals['text_length_bin'] = 'Total'\n",
    "\n",
    "combined = pd.concat([cross, platform_totals], ignore_index=True)\n",
    "\n",
    "combined['sort_order'] = combined['text_length_bin'].replace({'short': 0, 'medium': 1, 'long': 2, 'Total': 3})\n",
    "combined = combined.sort_values(['platform', 'sort_order']).drop(columns='sort_order')\n",
    "\n",
    "grand_total = pd.DataFrame({\n",
    "    'platform': ['Total'],\n",
    "    'text_length_bin': [''],\n",
    "    'pre': [combined['pre'].sum()],\n",
    "    'during': [combined['during'].sum()],\n",
    "    'post': [combined['post'].sum()]\n",
    "})\n",
    "\n",
    "final = pd.concat([combined, grand_total], ignore_index=True)\n",
    "\n",
    "final = final[['platform', 'text_length_bin', 'pre', 'during', 'post']]\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "final['Total'] = final[['pre', 'during', 'post']].sum(axis=1)\n",
    "\n",
    "final = final[['platform', 'text_length_bin', 'pre', 'during', 'post', 'Total']]\n",
    "final "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c3fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross = pd.crosstab(\n",
    "    index=[final_table['platform'], final_table['text_length_bin']],\n",
    "    columns=final_table['period'],\n",
    "    margins=True,\n",
    "    margins_name=\"Total\"\n",
    ").reset_index()\n",
    "cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7331f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d770b9",
   "metadata": {},
   "source": [
    "##### Scaling Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table[final_table[\"platform\"] == \"youtube\"][\"like_scaled\"].hist(bins=50, figsize=(8, 5))\n",
    "\n",
    "plt.title(\"Histogram of scaled likes\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86f9abe",
   "metadata": {},
   "source": [
    "Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2360f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning_object = data_cleaning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "ba2ae32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23874"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_comment_list = []\n",
    "for comment in all_comments:\n",
    "    clean_comment_list.append(cleaning_object.remove_greek_stopwords(text=comment))\n",
    "len(clean_comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f69698",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for sentence in clean_comment_list:\n",
    "        words = sentence.split()\n",
    "        all_words.extend(words)\n",
    "\n",
    "word_frequency = dict(Counter(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10144302",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(word_frequency.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    background_color='white',\n",
    "    colormap='inferno',\n",
    "    max_words=100\n",
    ").generate_from_frequencies(word_frequency)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f2c33c",
   "metadata": {},
   "source": [
    "##### Userwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "56ae4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_users_dict = dict(Counter(all_users_yt))\n",
    "reddit_users_dict = dict(Counter(all_users_reddit))\n",
    "ogov_users_dict = dict(Counter(all_users_ogov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f803c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_table = binned_cumulative_table(yt_users_dict, step=10)\n",
    "reddit_table = binned_cumulative_table(reddit_users_dict, step=10)\n",
    "ogov_table = binned_cumulative_table(ogov_users_dict, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d90a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yt_table.to_latex(index=False))\n",
    "print(reddit_table.to_latex(index=False))\n",
    "print(ogov_table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65312a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binned_cumulative_table(yt_table, title=\"YouTube - Cumulative Percentage of Users by Comment\")\n",
    "plot_binned_cumulative_table(reddit_table, title=\"Reddit - Cumulative Percentage of Users by Comment\")\n",
    "plot_binned_cumulative_table(ogov_table, title=\"OpenGov - Cumulative Percentage of Users by Comment\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf89eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_binned_cumulative_tables({\n",
    "    \"YouTube\": yt_table,\n",
    "    \"Reddit\": reddit_table,\n",
    "    \"OpenGov\": ogov_table\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71a38ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "821"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reddit_users_dict) # 3127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_user_comment_counts(reddit_users_dict, title=\"Reddit user-comment distribution\", top_n=11)\n",
    "plot_user_comment_counts(yt_users_dict, title=\"YouTube user-comment distribution\", top_n=10)\n",
    "plot_user_comment_counts(ogov_users_dict, title=\"OpenGov user-comment distribution\", top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277c918",
   "metadata": {},
   "source": [
    "##### Timewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d04feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_datetime_frequencies(data_dict, title=\"Year-Month Frequency Plot\", color_code='C0'):\n",
    "    \"\"\"\n",
    "    Accepts year-month strings ('YYYY-MM') as keys and plots frequency over time.\n",
    "\n",
    "    Args:\n",
    "        data_dict (dict): {year_month_str: count}\n",
    "        title (str): Title for the plot\n",
    "    \"\"\"\n",
    "    data = [(datetime.strptime(k, \"%Y-%m\"), v) for k, v in data_dict.items()]\n",
    "    \n",
    "    data.sort(key=lambda x: x[0])\n",
    "    \n",
    "    x_vals = [item[0] for item in data]\n",
    "    y_vals = [item[1] for item in data]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(x_vals, y_vals, marker='o', linestyle='-', color=color_code)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Year–Month\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def greek_dates_to_year_month(dates):\n",
    "    \"\"\"\n",
    "    Converts a list of Greek date strings to ['YYYY-MM', ...]\n",
    "    \"\"\"\n",
    "    greek_months = {\n",
    "        \"Ιανουαρίου\": \"01\",\n",
    "        \"Φεβρουαρίου\": \"02\",\n",
    "        \"Μαρτίου\": \"03\",\n",
    "        \"Απριλίου\": \"04\",\n",
    "        \"Μαΐου\": \"05\",\n",
    "        \"Ιουνίου\": \"06\",\n",
    "        \"Ιουλίου\": \"07\",\n",
    "        \"Αυγούστου\": \"08\",\n",
    "        \"Σεπτεμβρίου\": \"09\",\n",
    "        \"Οκτωβρίου\": \"10\",\n",
    "        \"Νοεμβρίου\": \"11\",\n",
    "        \"Δεκεμβρίου\": \"12\"\n",
    "    }\n",
    "\n",
    "    result = []\n",
    "    for date_str in dates:\n",
    "        try:\n",
    "            day, month_name, rest = date_str.strip().split(\" \", 2)\n",
    "            year = rest.split(\",\")[0].strip()\n",
    "            month = greek_months.get(month_name)\n",
    "            if year and month:\n",
    "                result.append(f\"{year}-{month}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping invalid date: {date_str} → {e}\")\n",
    "            continue\n",
    "    return result\n",
    "\n",
    "def build_quarterly_frequency_table(month_count_dict):\n",
    "    \"\"\"\n",
    "    Groups a month:count dictionary by quarter and returns counts and percentages.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(list(month_count_dict.items()), columns=[\"Month\", \"Count\"])\n",
    "    df[\"Month\"] = pd.to_datetime(df[\"Month\"])\n",
    "    df[\"Quarter\"] = df[\"Month\"].dt.to_period(\"Q\").astype(str)\n",
    "    quarter_df = df.groupby(\"Quarter\", as_index=False)[\"Count\"].sum()\n",
    "    total = quarter_df[\"Count\"].sum()\n",
    "    quarter_df[\"Percentage\"] = (quarter_df[\"Count\"] / total * 100).round(2)\n",
    "\n",
    "    return quarter_df.sort_values(\"Quarter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9aa5e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_reddit = []\n",
    "all_time_reddit_dynamic = []\n",
    "for element in reddit_clean:\n",
    "    for comment in element[\"comments\"]:\n",
    "        all_time_reddit.append(comment[\"published_at\"])\n",
    "        all_time_reddit_dynamic.append({comment[\"published_at\"]: comment[\"like_count\"]})\n",
    "\n",
    "all_time_yt = []\n",
    "all_time_yt_dynamic = []\n",
    "for element in youtube_clean:\n",
    "    for comment in element[\"comments\"]:\n",
    "        all_time_yt.append(comment[\"published_at\"])\n",
    "        all_time_yt_dynamic.append({comment[\"published_at\"]: comment[\"like_count\"]})\n",
    "\n",
    "all_time_ogov = []\n",
    "for element in ogov_clean:\n",
    "        all_time_ogov.append(element[\"date_published\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "80a8bb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_reddit_formated = [datetime.fromisoformat(d).strftime(\"%Y-%m\") for d in all_time_reddit]\n",
    "all_time_yt_formated = [datetime.fromisoformat(d).strftime(\"%Y-%m\") for d in all_time_yt]\n",
    "all_time_ogov_formated = greek_dates_to_year_month(all_time_ogov) \n",
    "\n",
    "all_time_reddit_dynamic_formatted = [\n",
    "    {datetime.fromisoformat(k).strftime(\"%Y-%m\"): v}\n",
    "    for d in all_time_reddit_dynamic\n",
    "    for k, v in d.items()\n",
    "]\n",
    "\n",
    "all_time_yt_dynamic_formated = [\n",
    "    {datetime.fromisoformat(k).strftime(\"%Y-%m\"): v}\n",
    "    for d in all_time_yt_dynamic\n",
    "    for k, v in d.items()\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6beab1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_yt_dynamic_formated_d = defaultdict(int)\n",
    "for d in all_time_yt_dynamic_formated:\n",
    "    for k, v in d.items():\n",
    "        all_time_yt_dynamic_formated_d[k] += v\n",
    "all_time_yt_dynamic_formated_dict = dict(all_time_yt_dynamic_formated_d)\n",
    "\n",
    "all_time_reddit_dynamic_formatted_d = defaultdict(int)\n",
    "for d in all_time_reddit_dynamic_formatted:\n",
    "    for k, v in d.items():\n",
    "        all_time_reddit_dynamic_formatted_d[k] += v\n",
    "all_time_reddit_dynamic_formatted_dict = dict(all_time_reddit_dynamic_formatted_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8894c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_time_dict = dict(Counter(all_time_yt_formated))\n",
    "reddit_time_dict = dict(Counter(all_time_reddit_formated))\n",
    "ogov_time_dict = dict(Counter(all_time_ogov_formated)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_quarter_table_yt = build_quarterly_frequency_table(yt_time_dict)\n",
    "time_quarter_table_reddit = build_quarterly_frequency_table(reddit_time_dict)\n",
    "\n",
    "print(time_quarter_table_yt.to_latex(index=False))\n",
    "print(time_quarter_table_reddit.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29da516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_datetime_frequencies(yt_time_dict, title=\"YouTube Comment Frequency\")\n",
    "plot_datetime_frequencies(reddit_time_dict, title=\"Reddit Comment Frequency\", color_code='C1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8f28b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_platform_frequencies_clean(df, title=\"Monthly Comment Frequency by Platform\", color_map=None):\n",
    "    \"\"\"\n",
    "    Plots monthly frequency line plot per platform with year-only x-axis ticks and equal spacing.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Must have 'platform' and 'date_mini' ('YYYY-MM') columns.\n",
    "        title (str): Plot title.\n",
    "        color_map (dict): Optional dict of platform -> color string (e.g., 'blue', 'orange').\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"date_mini\"] = pd.to_datetime(df[\"date_mini\"], format=\"%Y-%m\")\n",
    "\n",
    "    counts = df.groupby([\"platform\", \"date_mini\"]).size().reset_index(name=\"count\")\n",
    "    pivot = counts.pivot(index=\"date_mini\", columns=\"platform\", values=\"count\").fillna(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    for platform in pivot.columns:\n",
    "        plt.plot(\n",
    "            pivot.index,\n",
    "            pivot[platform],\n",
    "            marker='o',\n",
    "            label=platform,\n",
    "            color=color_map.get(platform, None) if color_map else None\n",
    "        )\n",
    "\n",
    "    years = pd.date_range(start=\"2014-01-01\", end=\"2025-12-01\", freq=\"YS\")\n",
    "\n",
    "    plt.xticks(\n",
    "        ticks=years,\n",
    "        labels=[d.strftime(\"%Y\") for d in years],\n",
    "        rotation=0\n",
    "    )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Year\")\n",
    "    plt.ylabel(\"Comment Count\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Platform\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a42714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {\n",
    "    \"reddit\": \"C1\",\n",
    "    \"youtube\": \"C0\",\n",
    "    \"opengov\": \"C2\"\n",
    "}\n",
    "plot_platform_frequencies_clean(final_table[final_table[\"platform\"] != \"opengov\"], color_map=color_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4311ebb5",
   "metadata": {},
   "source": [
    "##### Commentwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f0fc1668",
   "metadata": {},
   "outputs": [],
   "source": [
    "commentwise_df = final_table.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c3bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for plat, grp in commentwise_df.groupby('platform'):\n",
    "    arr = grp['like_scaled_norm'].dropna()\n",
    "    total = len(arr)\n",
    "    if total == 0:\n",
    "        continue\n",
    "\n",
    "    if arr.nunique() == 1:\n",
    "        interval = pd.Interval(arr.min(), arr.max(), closed='both')\n",
    "        bins = pd.IntervalIndex([interval])\n",
    "        binned = pd.cut(arr, bins=bins)\n",
    "    else:\n",
    "        try:\n",
    "            binned = pd.cut(arr, bins=20, include_lowest=True)\n",
    "        except ValueError:\n",
    "            binned = pd.qcut(arr, q=20, duplicates='drop')\n",
    "\n",
    "    freq = (\n",
    "        binned\n",
    "          .value_counts(sort=False)\n",
    "          .reset_index(name='count')\n",
    "          .rename(columns={'index':'like_scaled_norm_interval'})\n",
    "    )\n",
    "    freq['percentage'] = round(100 * freq['count'] / total,2)\n",
    "    freq['platform']   = plat\n",
    "\n",
    "    records.append(freq)\n",
    "\n",
    "freq_table = pd.concat(records, ignore_index=True)\n",
    "\n",
    "print(freq_table.to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "commentwise_df[\"like_scaled_norm\"].hist(bins=100, figsize=(10, 3))\n",
    "plt.title(\"Histogram of scaled likes\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bae5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = final_table.groupby(['platform', 'text_length_bin']).size().reset_index(name='count')\n",
    "total_per_platform = group_counts.groupby('platform')['count'].transform('sum')\n",
    "group_counts['percentage'] = 100 * group_counts['count'] / total_per_platform\n",
    "\n",
    "pivot_df = group_counts.pivot(index='text_length_bin', columns='platform', values='percentage').fillna(0)\n",
    "\n",
    "platform_order = list(pivot_df.columns)\n",
    "\n",
    "color_map = {\n",
    "    platform_order[0]: 'C2',\n",
    "    platform_order[1]: 'C1',\n",
    "    platform_order[2]: 'C0'\n",
    "}\n",
    "\n",
    "ax = pivot_df.plot(\n",
    "    kind='bar',\n",
    "    figsize=(10, 6),\n",
    "    color=[color_map[col] for col in pivot_df.columns]\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    for bar in container:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height + 0.5,\n",
    "                f\"{height:.1f}%\",\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=9\n",
    "            )\n",
    "\n",
    "plt.title(\"Percentage of Comment Length per Platform\")\n",
    "plt.xlabel(\"Text Length Bin\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Platform\")\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e57ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_counts = final_table.groupby(['period', 'text_length_bin']).size().reset_index(name='count')\n",
    "total_per_period = group_counts.groupby('period')['count'].transform('sum')\n",
    "group_counts['percentage'] = 100 * group_counts['count'] / total_per_period\n",
    "\n",
    "pivot_df = group_counts.pivot(index='text_length_bin', columns='period', values='percentage').fillna(0)\n",
    "\n",
    "period_order = [\"pre\", \"during\", \"post\"]\n",
    "color_map = {\n",
    "    period_order[0]: 'C31',\n",
    "    period_order[1]: 'C3',\n",
    "    period_order[2]: 'C28'\n",
    "}\n",
    "\n",
    "ax = pivot_df.plot(\n",
    "    kind='bar',\n",
    "    figsize=(10, 6),\n",
    "    color=[color_map[col] for col in pivot_df.columns]\n",
    ")\n",
    "\n",
    "for container in ax.containers:\n",
    "    for bar in container:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(\n",
    "                bar.get_x() + bar.get_width() / 2,\n",
    "                height + 0.5,\n",
    "                f\"{height:.1f}%\",\n",
    "                ha='center',\n",
    "                va='bottom',\n",
    "                fontsize=9\n",
    "            )\n",
    "\n",
    "plt.title(\"Percentage of Comment Length per Period\")\n",
    "plt.xlabel(\"Text Length Bin\")\n",
    "plt.ylabel(\"Percentage (%)\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title=\"Period\")\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffcacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_every_n_words(s: str, n: int = 10) -> list[str]:\n",
    "    words = s.split()\n",
    "    return [\" \".join(words[i:i+n]) for i in range(0, len(words), n)]\n",
    "\n",
    "matches = final_table[(final_table[\"text\"].str.contains(\"woke\", na=False)) & (final_table[\"text_length_bin\"] == \"short\")]\n",
    "txt = list(matches[\"text\"])\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe44b331",
   "metadata": {},
   "source": [
    "Comment weighted with like scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9512be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "period_order = [\"pre\", \"during\", \"post\"]\n",
    "color_map = {\n",
    "    period_order[0]: 'C31',\n",
    "    period_order[1]: 'C3',\n",
    "    period_order[2]: 'C28'\n",
    "}\n",
    "\n",
    "filtered = final_table[final_table['platform'] != 'opengov']\n",
    "\n",
    "top_comments = (\n",
    "    filtered\n",
    "      .sort_values('like_scaled_norm', ascending=False)\n",
    "      .groupby(['platform', 'period'], group_keys=False)\n",
    "      .head(100)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "text_bins = sorted(filtered['text_length_bin'].unique())\n",
    "periods   = period_order[:] \n",
    "\n",
    "platforms = top_comments['platform'].unique()\n",
    "fig, axes = plt.subplots(1, len(platforms),\n",
    "                         figsize=(5 * len(platforms), 5),\n",
    "                         sharey=True)\n",
    "\n",
    "if len(platforms) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (ax, plat) in enumerate(zip(axes, platforms)):\n",
    "    sub = top_comments[top_comments['platform'] == plat]\n",
    "    pivot = (\n",
    "        sub\n",
    "         .groupby(['text_length_bin','period'])\n",
    "         .size()\n",
    "         .unstack(fill_value=0)\n",
    "         .reindex(index=text_bins, columns=periods, fill_value=0)\n",
    "    )\n",
    "    pivot_pct = pivot.div(pivot.sum(axis=0), axis=1) * 100\n",
    "\n",
    "    colors = [color_map[period] for period in pivot_pct.columns]\n",
    "\n",
    "    pivot_pct.plot(\n",
    "        kind='bar',\n",
    "        ax=ax,\n",
    "        width=0.8,\n",
    "        color=colors,\n",
    "        legend=(i == len(platforms) - 1)\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"{plat.capitalize()} Top 100 Rated Comments Distribution\")\n",
    "    ax.set_xlabel(\"Text Length\")\n",
    "    ax.set_ylabel(\"Percent of Top 100 Comments (%)\")\n",
    "    ax.tick_params(axis='x', rotation=0)\n",
    "\n",
    "    if i == len(platforms) - 1:\n",
    "        ax.legend(title=\"Period\", loc='upper left', bbox_to_anchor=(1.02, 1))\n",
    "\n",
    "    for container in ax.containers:\n",
    "        for bar in container:\n",
    "            h = bar.get_height()\n",
    "            if h > 0:\n",
    "                ax.text(\n",
    "                    bar.get_x() + bar.get_width() / 2,\n",
    "                    h + 1,\n",
    "                    f\"{h:.1f}%\",\n",
    "                    ha='center',\n",
    "                    va='bottom',\n",
    "                    fontsize=7\n",
    "                )\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.8])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
