{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db744599",
   "metadata": {},
   "source": [
    "## Topic Modeling - BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0b44ad",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533c08aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import math\n",
    "import re\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import *\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.manifold import trustworthiness\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import unicodedata \n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('..')))\n",
    "from utils.text_analysis_functions import data_cleaning\n",
    "from utils.modeling_helpers import split_text_natural_or_equal, clean_text, get_topic_words, summarize_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df28e5",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf4920",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"nlpaueb/bert-base-greek-uncased-v1\",\n",
    "    use_fast=True\n",
    ")\n",
    "\n",
    "cleaning_object = data_cleaning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a344d",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1946516",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))) + \"\\\\working_data\\\\transformed_dataset.csv\"\n",
    "embeddings_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))) + \"\\\\working_data\\\\my_data_embeddings.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de22639",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path)[[\"text\",\"word_count\",\"period\"]]\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25806185",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ba6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"doc_id\"]     = data.index\n",
    "data[\"text_clean\"] = data[\"text\"].apply(lambda txt: clean_text(cleaning_object, txt))\n",
    "data[\"chunks\"]     = data[\"text_clean\"].apply(\n",
    "    lambda txt: split_text_natural_or_equal(tokenizer, txt, max_length=512)\n",
    ")\n",
    "\n",
    "data_exploded = data.explode(\"chunks\").reset_index(drop=True)\n",
    "data_exploded[\"chunk_id\"] = data_exploded.index\n",
    "\n",
    "mask = data_exploded[\"chunks\"].str.split().str.len() >= 3\n",
    "data_exploded = data_exploded[mask].reset_index(drop=True)\n",
    "\n",
    "data_exploded.to_pickle(\"exploded_chunks.pkl\")\n",
    "\n",
    "final_chunks = data_exploded[\"chunks\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbd97a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20288"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7017aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.load(embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7ca555",
   "metadata": {},
   "source": [
    "### Step 01 - Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed7c6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e4f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12deffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_sentence_model = SentenceTransformer(\"nlpaueb/bert-base-greek-uncased-v1\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1050401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = transformer_sentence_model.encode(\n",
    "    final_chunks,\n",
    "    batch_size= 32,\n",
    "    show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a5efc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(embeddings) == len(data_exploded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d661217",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_norm = normalize(embeddings, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "793e4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(embeddings_path, embeddings) # save embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60633b35",
   "metadata": {},
   "source": [
    "### Step 02 - Dimensionality Reduction & Clustering Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29cafb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20288"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7759dd7",
   "metadata": {},
   "source": [
    "Run ONCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11858eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params by silhouette: n_neighbors        5.000000\n",
      "min_dist           0.000000\n",
      "n_components       5.000000\n",
      "trustworthiness    0.910923\n",
      "silhouette         0.562084\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"n_neighbors\": [5, 15, 50],\n",
    "    \"min_dist\":    [0.0, 0.1, 0.5],\n",
    "    \"n_components\":[2, 5, 10]\n",
    "}\n",
    "\n",
    "records = []\n",
    "for n_nb in param_grid[\"n_neighbors\"]:\n",
    "    for md in param_grid[\"min_dist\"]:\n",
    "        for nc in param_grid[\"n_components\"]:\n",
    "            um = UMAP(\n",
    "                n_neighbors=n_nb,\n",
    "                min_dist=md,\n",
    "                n_components=nc,\n",
    "                metric=\"cosine\",\n",
    "                random_state=42\n",
    "            )\n",
    "            X_red = um.fit_transform(embeddings)\n",
    "\n",
    "            tw = trustworthiness(embeddings, X_red, n_neighbors=5)\n",
    "\n",
    "            clusterer = HDBSCAN(min_cluster_size=10, metric='euclidean')\n",
    "            labels = clusterer.fit_predict(X_red)\n",
    "            # silhouette only on non-noise\n",
    "            mask = labels >= 0\n",
    "            if mask.sum() > 1:\n",
    "                sil = silhouette_score(X_red[mask], labels[mask])\n",
    "            else:\n",
    "                sil = np.nan\n",
    "\n",
    "            records.append({\n",
    "                \"n_neighbors\": n_nb,\n",
    "                \"min_dist\": md,\n",
    "                \"n_components\": nc,\n",
    "                \"trustworthiness\": tw,\n",
    "                \"silhouette\": sil\n",
    "            })\n",
    "\n",
    "df_scores = pd.DataFrame(records)\n",
    "\n",
    "best = df_scores.sort_values(\"silhouette\", ascending=False).iloc[0]\n",
    "print(\"Best params by silhouette:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1a1f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality_reduction_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))) + \"\\\\working_data\\\\umap_fine_tuning_results.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9c02ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv(dimensionality_reduction_path ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.sort_values(by=[\"silhouette\"], ascending=False)[df_scores[\"silhouette\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62af1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.read_csv(dimensionality_reduction_path)\n",
    "df_scores_selection = df_scores.copy()\n",
    "df_scores_selection[\"aggregate_score_mag\"] = df_scores_selection[\"trustworthiness\"] + df_scores_selection[\"silhouette\"]\n",
    "df_scores_selection[\"aggregate_score_avg\"] = (df_scores_selection[\"trustworthiness\"] + df_scores_selection[\"silhouette\"]) / 2\n",
    "df_scores_selection_sorted = df_scores_selection.sort_values(by=[\"aggregate_score_avg\"], ascending=False)[df_scores[\"silhouette\"] > 0]\n",
    "df_scores_selection_sorted.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "503577bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(\n",
    "        n_neighbors=5,\n",
    "        min_dist=0,\n",
    "        n_components=2,\n",
    "        metric=\"cosine\",\n",
    "        random_state=42\n",
    "    )\n",
    "reduced_embeddings = umap_model.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = reduced_embeddings \n",
    "\n",
    "param_grid = {\n",
    "    \"min_cluster_size\": [3, 5, 10, 20],\n",
    "    \"min_samples\":      [1, 3, 5]\n",
    "}\n",
    "\n",
    "records = []\n",
    "for mcs in param_grid[\"min_cluster_size\"]:\n",
    "    for ms in param_grid[\"min_samples\"]:\n",
    "        clusterer = HDBSCAN(\n",
    "            min_cluster_size=mcs,\n",
    "            min_samples=ms,\n",
    "            metric='euclidean'\n",
    "        )\n",
    "        labels = clusterer.fit_predict(X2)\n",
    "        \n",
    "        mask = labels >= 0\n",
    "        sil = silhouette_score(X2[mask], labels[mask]) if mask.sum() > 1 else np.nan\n",
    "        \n",
    "        unique_clusters = set(labels[mask])\n",
    "        n_clusters = len(unique_clusters)\n",
    "        n_noise = int((labels == -1).sum())\n",
    "        \n",
    "        records.append({\n",
    "            \"min_cluster_size\": mcs,\n",
    "            \"min_samples\": ms,\n",
    "            \"n_clusters\": n_clusters,\n",
    "            \"n_noise\": n_noise,\n",
    "            \"silhouette\": sil\n",
    "        })\n",
    "\n",
    "df_scores = pd.DataFrame(records)\n",
    "\n",
    "best = df_scores.sort_values(\"silhouette\", ascending=False).iloc[0]\n",
    "best_mcs, best_ms = best[\"min_cluster_size\"], best[\"min_samples\"]\n",
    "\n",
    "best_clusterer = HDBSCAN(\n",
    "    min_cluster_size=int(best_mcs),\n",
    "    min_samples=int(best_ms),\n",
    "    metric='euclidean'\n",
    ")\n",
    "best_labels = best_clusterer.fit_predict(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.sort_values(by=[\"silhouette\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71880cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_path = os.path.dirname(os.path.dirname(os.path.dirname(os.getcwd()))) + \"\\\\working_data\\\\hdbscan_fine_tuning_results.csv\"\n",
    "df_scores.to_csv(clustering_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = HDBSCAN(\n",
    "    min_cluster_size=20,\n",
    "    min_samples=3,\n",
    "    metric='euclidean',\n",
    "    prediction_data=True\n",
    ")\n",
    "labels = clusterer.fit_predict(reduced_embeddings)\n",
    "\n",
    "# convert labels to a Python set for unique IDs\n",
    "unique_labels = set(labels.tolist())\n",
    "# remove noise label\n",
    "unique_labels.discard(-1)\n",
    "n_clusters = len(unique_labels)\n",
    "# points were labeled as noise\n",
    "n_noise = int((labels == -1).sum())\n",
    "\n",
    "print(f\"Found {n_clusters} clusters and {n_noise} noise points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24919e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_docs = len(labels)\n",
    "num_noise  = (labels == -1).sum()\n",
    "print(f\"Noise fraction: {num_noise/total_docs:.1%}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b2fb60",
   "metadata": {},
   "source": [
    "### Step 03 - Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4acfeb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(\n",
    "        n_neighbors=5,\n",
    "        min_dist=0,\n",
    "        n_components=2,\n",
    "        metric=\"cosine\",\n",
    "        random_state=42\n",
    "    )\n",
    "reduced_embeddings = umap_model.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b41ad",
   "metadata": {},
   "source": [
    "### Step 04 - Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a6b1dcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.41869235)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model = HDBSCAN(\n",
    "            min_cluster_size=20,\n",
    "            min_samples=3,\n",
    "            metric='euclidean',\n",
    "            prediction_data=True\n",
    "            )\n",
    "labels = cluster_model.fit_predict(reduced_embeddings)\n",
    "mask = labels >= 0\n",
    "silhouette_score(reduced_embeddings[mask], labels[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671394cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = reduced_embeddings # 2D UMAP coordinates\n",
    "labels = labels # HDBSCAN labels\n",
    "\n",
    "# noise\n",
    "noise_mask = labels == -1\n",
    "cluster_mask = ~noise_mask\n",
    "\n",
    "# top 10 clusters\n",
    "counts = pd.Series(labels[cluster_mask]).value_counts()\n",
    "top_k = counts.nlargest(30).index\n",
    "\n",
    "# other clusters\n",
    "others_mask = cluster_mask & ~np.isin(labels, top_k)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "# noise in light gray\n",
    "plt.scatter(\n",
    "    X2[noise_mask,0], X2[noise_mask,1],\n",
    "    c=\"#dddddd\", s=10, label=\"noise\", alpha=0.5\n",
    ")\n",
    "\n",
    "# non specified clusters in dark gray\n",
    "plt.scatter(\n",
    "    X2[others_mask,0], X2[others_mask,1],\n",
    "    c=\"#bbbbbb\", s=10, label=\"others\", alpha=0.5\n",
    ")\n",
    "\n",
    "# top 10 clusters with colors\n",
    "palette = sns.color_palette(\"tab10\", n_colors=len(top_k))\n",
    "for cluster_id, color in zip(top_k, palette):\n",
    "    mask = labels == cluster_id\n",
    "    plt.scatter(\n",
    "        X2[mask,0], X2[mask,1],\n",
    "        c=[color], s=20, label=f\"cluster {cluster_id}\", alpha=0.8\n",
    "    )\n",
    "\n",
    "plt.legend(\n",
    "    bbox_to_anchor=(1.05,1),\n",
    "    loc=\"upper left\",\n",
    "    fontsize=8,\n",
    "    frameon=False\n",
    ")\n",
    "plt.xlabel(\"UMAP 1\")\n",
    "plt.ylabel(\"UMAP 2\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7443d967",
   "metadata": {},
   "source": [
    "### Step 05 - Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24557af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2), stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e091a5de",
   "metadata": {},
   "source": [
    "### Step 06 - BERTopic Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcd4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(\n",
    "    embedding_model=None,\n",
    "    umap_model=umap_model,\n",
    "    hdbscan_model=cluster_model,\n",
    "    vectorizer_model=vectorizer,\n",
    "    language=\"greek\",\n",
    "    calculate_probabilities=True,\n",
    "    nr_topics=14,\n",
    "    top_n_words=10,\n",
    ")\n",
    "topics, probs = topic_model.fit_transform(documents=final_chunks, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac5af58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = topic_model.visualize_barchart(\n",
    "    top_n_topics=20,\n",
    "    n_words=20\n",
    ")\n",
    "fig.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968d629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f6926",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.save(\"BERTopic_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64684b20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_thesis_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
